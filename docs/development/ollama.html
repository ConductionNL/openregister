<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-development/ollama" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Ollama Setup and Configuration | Open Register</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://openregisters.app/docs/development/ollama"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Ollama Setup and Configuration | Open Register"><meta data-rh="true" name="description" content="Guide to setting up and configuring Ollama for OpenRegister AI features"><meta data-rh="true" property="og:description" content="Guide to setting up and configuring Ollama for OpenRegister AI features"><meta data-rh="true" name="keywords" content="Open Register,Ollama,LLM,GPU,AI"><link data-rh="true" rel="canonical" href="https://openregisters.app/docs/development/ollama"><link data-rh="true" rel="alternate" href="https://openregisters.app/docs/development/ollama" hreflang="en"><link data-rh="true" rel="alternate" href="https://openregisters.app/docs/development/ollama" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.ee795deb.css">
<script src="/assets/js/runtime~main.4b882c54.js" defer="defer"></script>
<script src="/assets/js/main.fd0dd4e2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Open Register Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Open Register Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Open Register</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Integrations">Documentation</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/api">API Documentation</a><a href="https://github.com/conductionnl/openregister" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Integrations">Integrations Overview</a><button aria-label="Expand sidebar category &#x27;Integrations Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Development/Services">Development</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Features">Core Features</a><button aria-label="Expand sidebar category &#x27;Core Features&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Technical/vectorization-architecture">Technical</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/UseCases/clientRegisters">UseCases</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/api/bulk-operations">api</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/developers/external-app-optimization">developers</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/development/deeplinking-spot">development</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/deeplinking-spot">Deep Linking and SPOT Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/git-submodules">Git Submodules Development Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/services-architecture">Service Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/performance-optimization">Performance Optimization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/development/ollama">Ollama Setup and Configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/tool-registration">Tool Registration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/tool-registration-testing">Tool Testing Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/docker-services">Docker Services Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/DOCKER_SERVICES_SUMMARY">Docker Services - Quick Reference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/presidio-setup">Presidio Setup for Dutch Language</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/dolphin-deployment">Dolphin Document Parser Deployment (Optional)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/huggingface-tgi-setup">Hugging Face TGI/vLLM Setup - OpenAI-Compatible API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/llphant-setup">LLPhant Installation Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/fulltextsearch-setup">Nextcloud Full Text Search Setup</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/solr-development">Solr Development Troubleshooting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/magic-mapper">MagicMapper - Dynamic Schema-Based Table Management</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/file-uploads-implementation">Integrated File Uploads Implementation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/security-architecture">Security Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/virus-scanning">Virus Scanning Setup</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/epic-milestones">Development Milestones</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/monitoring-testing">Monitoring &amp; Testing Implementation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/testing">Testing Improvements</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/api-validation">OpenAPI Specification Validation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/search-optimization">Search and Faceting Optimization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/rag-fix">RAG Semantic Search Fix</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/llphant-refactor">LLPhant Refactoring Plan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/text-extraction-refactoring">Text Extraction Refactoring Summary</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/development/api/files">api</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/object-service-refactoring">ObjectService Refactoring</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/development/tool-metadata-architecture">Tool Metadata Architecture - Documentation Update</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/features/ai">features</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/technical/vector-search-backends">technical</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/user/ai-conversations">user</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/user-guide/configuration/api-tokens">user-guide</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">development</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Ollama Setup and Configuration</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Using Ollama with OpenRegister</h1></header>
<p>OpenRegister supports Ollama for running local Large Language Models (LLMs) for AI-powered features like chat, agents, and RAG (Retrieval Augmented Generation).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-ollama">What is Ollama?<a href="#what-is-ollama" class="hash-link" aria-label="Direct link to What is Ollama?" title="Direct link to What is Ollama?">‚Äã</a></h2>
<p>Ollama allows you to run open-source LLMs locally on your machine, providing:</p>
<ul>
<li><strong>Privacy</strong>: Your data never leaves your infrastructure</li>
<li><strong>Cost-effective</strong>: No API costs for inference</li>
<li><strong>Customization</strong>: Run any compatible model</li>
<li><strong>Offline capability</strong>: Works without internet connection</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="technical-implementation">Technical Implementation<a href="#technical-implementation" class="hash-link" aria-label="Direct link to Technical Implementation" title="Direct link to Technical Implementation">‚Äã</a></h3>
<p>OpenRegister uses LLPhant&#x27;s native Ollama support, which provides:</p>
<ul>
<li><strong>Direct API Integration</strong>: Uses Ollama&#x27;s native <code>/api/</code> endpoints (not OpenAI-compatible layer)</li>
<li><strong>Better Performance</strong>: Optimized for Ollama&#x27;s specific API structure</li>
<li><strong>Simpler Configuration</strong>: No need for API key workarounds</li>
<li><strong>Full Feature Support</strong>: Native support for chat, embeddings, and function calling</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quick-start">Quick Start<a href="#quick-start" class="hash-link" aria-label="Direct link to Quick Start" title="Direct link to Quick Start">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-start-ollama-container">1. Start Ollama Container<a href="#1-start-ollama-container" class="hash-link" aria-label="Direct link to 1. Start Ollama Container" title="Direct link to 1. Start Ollama Container">‚Äã</a></h3>
<p>The Ollama container is included in the docker-compose configuration:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Start all services including Ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose up -d</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Or specifically start Ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose up -d ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-pull-a-model">2. Pull a Model<a href="#2-pull-a-model" class="hash-link" aria-label="Direct link to 2. Pull a Model" title="Direct link to 2. Pull a Model">‚Äã</a></h3>
<p>Pull one of the supported models:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Llama 3.2 (8B) - Recommended, best balance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull llama3.2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Llama 3.2 (3B) - Lighter alternative</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull llama3.2:3b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Mistral (7B) - Fast and efficient</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull mistral:7b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Phi-3 Mini (3.8B) - Lightweight option</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull phi3:mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># CodeLlama (7B) - Optimized for code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull codellama:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-configure-openregister">3. Configure OpenRegister<a href="#3-configure-openregister" class="hash-link" aria-label="Direct link to 3. Configure OpenRegister" title="Direct link to 3. Configure OpenRegister">‚Äã</a></h3>
<ol>
<li>Navigate to <strong>Settings</strong> ‚Üí <strong>OpenRegister</strong> ‚Üí <strong>LLM Configuration</strong></li>
<li>Select <strong>Ollama</strong> as the chat provider</li>
<li>Configure the settings based on your setup:</li>
</ol>
<p><strong>Integrated Setup (docker-compose.yml):</strong></p>
<ul>
<li><strong>Ollama URL</strong>: <code>http://openregister-ollama:11434</code> ‚ö†Ô∏è <strong>NOT</strong> <code>http://localhost:11434</code></li>
<li><strong>Chat Model</strong>: <code>llama3.2:latest</code> (or model you pulled with full name including tag)</li>
<li><strong>Embedding Model</strong>: <code>nomic-embed-text:latest</code></li>
<li><strong>Why not localhost?</strong> OpenRegister runs inside Nextcloud container; use container name instead</li>
</ul>
<p><strong>Standalone Setup (docker-compose.ollama.yml):</strong></p>
<ul>
<li><strong>Via Docker Network</strong> (recommended): <code>http://standalone-ollama:11434</code> (after connecting networks)</li>
<li><strong>Via Host IP</strong>: <code>http://YOUR_HOST_IP:11434</code> (e.g., <code>http://192.168.1.100:11434</code>)</li>
<li><strong>Different Host</strong>: <code>http://your-server-ip:11434</code></li>
<li>‚ùå <strong>NOT</strong>: <code>http://localhost:11434</code> (won&#x27;t work from inside container)</li>
<li><strong>Chat Model</strong>: <code>llama3.2:latest</code> (use full name with tag)</li>
<li><strong>Embedding Model</strong>: <code>nomic-embed-text:latest</code></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-pull-embedding-model-for-rag">4. Pull Embedding Model (for RAG)<a href="#4-pull-embedding-model-for-rag" class="hash-link" aria-label="Direct link to 4. Pull Embedding Model (for RAG)" title="Direct link to 4. Pull Embedding Model (for RAG)">‚Äã</a></h3>
<p>If using RAG features, pull an embedding model:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Nomic Embed Text - Recommended for embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull nomic-embed-text:latest</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Alternative: all-minilm (smaller, faster)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull all-minilm:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuration-details">Configuration Details<a href="#configuration-details" class="hash-link" aria-label="Direct link to Configuration Details" title="Direct link to Configuration Details">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ollama-service-configuration">Ollama Service Configuration<a href="#ollama-service-configuration" class="hash-link" aria-label="Direct link to Ollama Service Configuration" title="Direct link to Ollama Service Configuration">‚Äã</a></h3>
<p>The Ollama service is configured in <code>docker-compose.yml</code>:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">ollama</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ollama/ollama</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">latest</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">container_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openregister</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restart</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> always</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ports</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;11434:11434&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ollama</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">/root/.ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">environment</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_HOST=0.0.0.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_NUM_PARALLEL=4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_KEEP_ALIVE=30m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">deploy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 16G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">reservations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 8G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> all</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">capabilities</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">healthcheck</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">test</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;CMD-SHELL&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;curl -f http://localhost:11434/api/tags || exit 1&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">interval</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 30s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">timeout</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 10s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">retries</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="accessing-ollama">Accessing Ollama<a href="#accessing-ollama" class="hash-link" aria-label="Direct link to Accessing Ollama" title="Direct link to Accessing Ollama">‚Äã</a></h3>
<p><strong>Important: Docker Container Communication</strong></p>
<p>When configuring Ollama in OpenRegister, you MUST use the Docker service name, not <code>localhost</code>:</p>
<ul>
<li>‚úÖ <strong>Correct (from Nextcloud container)</strong>: <code>http://openregister-ollama:11434</code> or <code>http://ollama:11434</code></li>
<li>‚ùå <strong>Wrong</strong>: <code>http://localhost:11434</code> (this only works from your host machine, not from inside containers)</li>
</ul>
<p><strong>Access Points:</strong></p>
<ul>
<li><strong>From host machine</strong> (terminal, browser): <code>http://localhost:11434</code></li>
<li><strong>From Nextcloud container</strong> (OpenRegister settings): <code>http://openregister-ollama:11434</code> or <code>http://ollama:11434</code></li>
<li><strong>From other Docker containers</strong>: <code>http://openregister-ollama:11434</code></li>
</ul>
<p><strong>Why?</strong> Inside a Docker container, <code>localhost</code> refers to the container itself, not your host machine. Containers communicate with each other using service names defined in docker-compose.yml.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-naming">Model Naming<a href="#model-naming" class="hash-link" aria-label="Direct link to Model Naming" title="Direct link to Model Naming">‚Äã</a></h3>
<p><strong>Important</strong>: Ollama models must be referenced with their full name including version tags:</p>
<ul>
<li>‚úÖ <strong>Correct</strong>: <code>mistral:7b</code>, <code>llama3.2:latest</code>, <code>phi3:mini</code></li>
<li>‚ùå <strong>Wrong</strong>: <code>mistral</code>, <code>llama3.2</code>, <code>phi3</code> (without tags)</li>
</ul>
<p>The OpenRegister UI dropdown shows full model names with tags to ensure compatibility.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="recommended-models">Recommended Models<a href="#recommended-models" class="hash-link" aria-label="Direct link to Recommended Models" title="Direct link to Recommended Models">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="for-chat--agents">For Chat &amp; Agents<a href="#for-chat--agents" class="hash-link" aria-label="Direct link to For Chat &amp; Agents" title="Direct link to For Chat &amp; Agents">‚Äã</a></h3>
<table><thead><tr><th>Model</th><th>Size</th><th>RAM Required</th><th>Speed</th><th>Quality</th><th>Use Case</th></tr></thead><tbody><tr><td><strong>llama3.2<!-- -->:latest</strong> ‚≠ê</td><td>4.7GB</td><td>8-16GB</td><td>Fast</td><td>Excellent</td><td><strong>RECOMMENDED</strong> - Latest, best balance</td></tr><tr><td><strong>llama3.2:3b</strong></td><td>2.0GB</td><td>4-8GB</td><td>Very Fast</td><td>Very Good</td><td>Lighter, faster alternative</td></tr><tr><td><strong>llama3.1<!-- -->:latest</strong></td><td>4.7GB</td><td>8-16GB</td><td>Fast</td><td>Excellent</td><td>Previous gen, still great</td></tr><tr><td><strong>llama3.2:70b</strong> üî•</td><td>40GB</td><td>64-80GB</td><td>Slow</td><td>Best</td><td><strong>HIGH-END</strong> - Maximum quality</td></tr><tr><td><strong>mistral:7b</strong></td><td>4.1GB</td><td>8GB</td><td>Very Fast</td><td>Very Good</td><td>Fast responses</td></tr><tr><td><strong>phi3<!-- -->:mini</strong></td><td>2.3GB</td><td>4GB</td><td>Very Fast</td><td>Good</td><td>Low-resource environments</td></tr><tr><td><strong>codellama<!-- -->:latest</strong></td><td>3.8GB</td><td>8GB</td><td>Fast</td><td>Excellent (code)</td><td>Code generation/analysis</td></tr></tbody></table>
<p><strong>Memory Configuration Notes:</strong></p>
<ul>
<li>Our docker-compose files are configured with <strong>16GB limit</strong> (suitable for 8B models)</li>
<li>For 70B models, increase memory limit to <strong>80GB</strong> in docker-compose</li>
<li>Shared memory (<code>shm_size</code>) set to <strong>2GB</strong> for efficient model loading</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="for-embeddings-rag">For Embeddings (RAG)<a href="#for-embeddings-rag" class="hash-link" aria-label="Direct link to For Embeddings (RAG)" title="Direct link to For Embeddings (RAG)">‚Äã</a></h3>
<table><thead><tr><th>Model</th><th>Size</th><th>Dimensions</th><th>Use Case</th></tr></thead><tbody><tr><td><strong>nomic-embed-text<!-- -->:latest</strong></td><td>274MB</td><td>768</td><td>Recommended for most uses</td></tr><tr><td><strong>all-minilm<!-- -->:latest</strong></td><td>45MB</td><td>384</td><td>Lightweight, faster</td></tr><tr><td><strong>mxbai-embed-large<!-- -->:latest</strong></td><td>670MB</td><td>1024</td><td>Highest quality</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-support">GPU Support<a href="#gpu-support" class="hash-link" aria-label="Direct link to GPU Support" title="Direct link to GPU Support">‚Äã</a></h2>
<p>GPU acceleration provides <strong>10-100x speedup</strong> for model inference, dramatically improving response times and enabling larger models to run smoothly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h3>
<ol>
<li><strong>NVIDIA GPU</strong> with CUDA support (check compatibility at <a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/cuda-gpus</a>)</li>
<li><strong>NVIDIA drivers</strong> installed on Windows/Linux host</li>
<li><strong>WSL2</strong> (if using Windows with WSL)</li>
<li><strong>NVIDIA Container Toolkit</strong> for Docker</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verify-wsl-gpu-support-windows--wsl">Verify WSL GPU Support (Windows + WSL)<a href="#verify-wsl-gpu-support-windows--wsl" class="hash-link" aria-label="Direct link to Verify WSL GPU Support (Windows + WSL)" title="Direct link to Verify WSL GPU Support (Windows + WSL)">‚Äã</a></h3>
<p>First, check if your GPU is accessible from WSL2:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check GPU is visible in WSL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should show your GPU, driver version, and CUDA version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Example output:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># NVIDIA-SMI 546.30    Driver Version: 546.30    CUDA Version: 12.3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># GPU Name: NVIDIA GeForce RTX 3070 Laptop GPU</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If &#x27;nvidia-smi&#x27; is not found, you need to:</p>
<ol>
<li>Install latest NVIDIA drivers on Windows host</li>
<li>Update WSL2 kernel: <code>wsl --update</code></li>
<li>Restart WSL: <code>wsl --shutdown</code> then reopen</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verify-docker-gpu-support">Verify Docker GPU Support<a href="#verify-docker-gpu-support" class="hash-link" aria-label="Direct link to Verify Docker GPU Support" title="Direct link to Verify Docker GPU Support">‚Äã</a></h3>
<p>Check if Docker can access the GPU:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Test GPU access from Docker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker run --rm --gpus all nvidia/cuda:12.3.0-base-ubuntu20.04 nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should show the same GPU information</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># If this fails, install NVIDIA Container Toolkit:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="enable-gpu-in-docker-compose">Enable GPU in Docker Compose<a href="#enable-gpu-in-docker-compose" class="hash-link" aria-label="Direct link to Enable GPU in Docker Compose" title="Direct link to Enable GPU in Docker Compose">‚Äã</a></h3>
<p>The GPU configuration is already included in docker-compose files. Verify it contains:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">ollama</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ollama/ollama</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">latest</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">deploy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">reservations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> all  </span><span class="token comment" style="color:#999988;font-style:italic"># Use all available GPUs (or count: 1 for single GPU)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">capabilities</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="apply-gpu-configuration">Apply GPU Configuration<a href="#apply-gpu-configuration" class="hash-link" aria-label="Direct link to Apply GPU Configuration" title="Direct link to Apply GPU Configuration">‚Äã</a></h3>
<p>If using docker-compose:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Stop and remove the old container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker stop openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker rm openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Recreate with GPU support</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose up -d ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If using docker run (alternative method):</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Stop old container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker stop openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker rm openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Start with GPU support</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker run -d \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --name openregister-ollama \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --restart always \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -p 11434:11434 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -v openregister_ollama:/root/.ollama \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e OLLAMA_HOST=0.0.0.0 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e OLLAMA_NUM_PARALLEL=4 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e OLLAMA_KEEP_ALIVE=30m \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --shm-size=2gb \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --gpus all \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ollama/ollama:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verify-gpu-is-working">Verify GPU is Working<a href="#verify-gpu-is-working" class="hash-link" aria-label="Direct link to Verify GPU is Working" title="Direct link to Verify GPU is Working">‚Äã</a></h3>
<p>After restarting Ollama with GPU support:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 1. Check GPU is accessible inside container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should show GPU information from inside the container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2. Check Docker device configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker inspect openregister-ollama --format &#x27;{{json .HostConfig.DeviceRequests}}&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should show: [{&quot;Driver&quot;:&quot;&quot;,&quot;Count&quot;:-1,&quot;Capabilities&quot;:[[&quot;gpu&quot;]],&quot;Options&quot;:{}}]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 3. Check Ollama logs for GPU detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker logs openregister-ollama | grep -i gpu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should show lines like:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># inference compute id=GPU-xxx library=CUDA compute=8.6 name=CUDA0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># description=&quot;NVIDIA GeForce RTX 3070 Laptop GPU&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># total=&quot;8.0 GiB&quot; available=&quot;6.2 GiB&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 4. Test inference speed (should be much faster)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama run llama3.2:latest &quot;What is 2+2?&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-comparison">Performance Comparison<a href="#performance-comparison" class="hash-link" aria-label="Direct link to Performance Comparison" title="Direct link to Performance Comparison">‚Äã</a></h3>
<table><thead><tr><th>Mode</th><th>Loading Time</th><th>First Token</th><th>Tokens/sec</th><th>Use Case</th></tr></thead><tbody><tr><td><strong>CPU</strong></td><td>30-60s</td><td>5-10s</td><td>2-5</td><td>Testing only</td></tr><tr><td><strong>GPU</strong></td><td>2-5s</td><td>0.5-1s</td><td>50-200</td><td>Production use</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-troubleshooting">GPU Troubleshooting<a href="#gpu-troubleshooting" class="hash-link" aria-label="Direct link to GPU Troubleshooting" title="Direct link to GPU Troubleshooting">‚Äã</a></h3>
<p><strong>Issue: &#x27;nvidia-smi: command not found&#x27; in container</strong></p>
<p>This means GPU is NOT configured. Check:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Verify DeviceRequests is not null</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker inspect openregister-ollama --format &#x27;{{json .HostConfig.DeviceRequests}}&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># If null, container was created without GPU support</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Solution: Remove and recreate with --gpus flag or proper docker-compose config</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Issue: GPU not detected in Ollama logs</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check Ollama startup logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker logs openregister-ollama 2&gt;&amp;1 | grep -A 5 &quot;discovering available GPUs&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># If no GPU found, check:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1. NVIDIA drivers installed on host</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2. nvidia-smi works on host</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 3. Docker GPU support working (test with nvidia/cuda image)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Issue: &#x27;Failed to initialize NVML: Unknown Error&#x27;</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># This usually means driver mismatch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Solution: Update NVIDIA drivers on host machine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Then restart Docker and WSL:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wsl --shutdown</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Restart Docker Desktop</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Recreate Ollama container</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Issue: Out of VRAM</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check GPU memory usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># If VRAM is full:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1. Use smaller model (3B instead of 8B)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2. Reduce OLLAMA_MAX_LOADED_MODELS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 3. Set shorter OLLAMA_KEEP_ALIVE (e.g., 5m)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 4. Restart container to clear VRAM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker restart openregister-ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="standalone-setup">Standalone Setup<a href="#standalone-setup" class="hash-link" aria-label="Direct link to Standalone Setup" title="Direct link to Standalone Setup">‚Äã</a></h2>
<p>Running Ollama standalone is ideal for:</p>
<ul>
<li>üñ•Ô∏è <strong>Separate Hardware</strong>: Run on a more powerful machine with more RAM/GPU</li>
<li>üîß <strong>Production</strong>: Isolate AI workloads from application stack</li>
<li>üìä <strong>Scalability</strong>: Serve multiple OpenRegister instances from one Ollama</li>
<li>üí∞ <strong>Cost Optimization</strong>: Use a dedicated GPU machine only for AI</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="start-standalone-ollama">Start Standalone Ollama<a href="#start-standalone-ollama" class="hash-link" aria-label="Direct link to Start Standalone Ollama" title="Direct link to Start Standalone Ollama">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># From the openregister directory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose -f docker-compose.ollama.yml up -d</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose -f docker-compose.ollama.yml ps</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># View logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose -f docker-compose.ollama.yml logs -f ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configure-openregister-for-standalone">Configure OpenRegister for Standalone<a href="#configure-openregister-for-standalone" class="hash-link" aria-label="Direct link to Configure OpenRegister for Standalone" title="Direct link to Configure OpenRegister for Standalone">‚Äã</a></h3>
<p><strong>Option 1: Use Host IP Address (Simplest)</strong></p>
<ul>
<li>URL: <code>http://YOUR_HOST_IP:11434</code> (e.g., <code>http://192.168.1.100:11434</code>)</li>
<li>Model: <code>llama3.2:latest</code></li>
<li><strong>Find your IP</strong>: Run <code>hostname -I | awk &#x27;{print $1}&#x27;</code> on Linux/Mac or <code>ipconfig</code> on Windows</li>
</ul>
<p><strong>Option 2: Connect via Docker Network (Recommended for Production)</strong></p>
<p>First, connect the standalone Ollama container to your Nextcloud network:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Find your Nextcloud network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker network ls | grep master</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Connect standalone Ollama to that network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker network connect master_default standalone-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Verify connection from Nextcloud container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec master-nextcloud-1 curl -s http://standalone-ollama:11434/api/tags</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Then in OpenRegister settings:</p>
<ul>
<li>URL: <code>http://standalone-ollama:11434</code></li>
<li>Model: <code>llama3.2:latest</code></li>
</ul>
<p><strong>Option 3: Different Physical Machine</strong></p>
<ul>
<li>URL: <code>http://your-ollama-server-ip:11434</code></li>
<li>Model: <code>llama3.2:latest</code></li>
<li>Ensure port 11434 is accessible (firewall rules)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-ollama-features">Using Ollama Features<a href="#using-ollama-features" class="hash-link" aria-label="Direct link to Using Ollama Features" title="Direct link to Using Ollama Features">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-chat">1. Chat<a href="#1-chat" class="hash-link" aria-label="Direct link to 1. Chat" title="Direct link to 1. Chat">‚Äã</a></h3>
<p>Once configured, the chat feature works automatically:</p>
<ol>
<li>Go to any page in OpenRegister</li>
<li>Click the chat icon in the sidebar</li>
<li>Start a conversation with your local AI</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-rag-retrieval-augmented-generation">2. RAG (Retrieval Augmented Generation)<a href="#2-rag-retrieval-augmented-generation" class="hash-link" aria-label="Direct link to 2. RAG (Retrieval Augmented Generation)" title="Direct link to 2. RAG (Retrieval Augmented Generation)">‚Äã</a></h3>
<p>Enable RAG for agents to search your documents:</p>
<ol>
<li>Create/edit an agent</li>
<li>Enable <strong>RAG</strong> in agent settings</li>
<li>Configure:<!-- -->
<ul>
<li><strong>Search Mode</strong>: Vector, Hybrid, or Full-text</li>
<li><strong>Number of Sources</strong>: How many documents to retrieve</li>
<li><strong>Include Files</strong>: Search uploaded files</li>
<li><strong>Include Objects</strong>: Search OpenRegister objects</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-agents-with-tools">3. Agents with Tools<a href="#3-agents-with-tools" class="hash-link" aria-label="Direct link to 3. Agents with Tools" title="Direct link to 3. Agents with Tools">‚Äã</a></h3>
<p>Create agents that can interact with your data:</p>
<ol>
<li>Create a new agent</li>
<li>Enable tools:<!-- -->
<ul>
<li><strong>Register Tool</strong>: Query registers</li>
<li><strong>Schema Tool</strong>: Access schemas</li>
<li><strong>Objects Tool</strong>: Manipulate objects</li>
</ul>
</li>
<li>Set the system prompt</li>
<li>Chat with the agent</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="managing-models">Managing Models<a href="#managing-models" class="hash-link" aria-label="Direct link to Managing Models" title="Direct link to Managing Models">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="list-installed-models">List Installed Models<a href="#list-installed-models" class="hash-link" aria-label="Direct link to List Installed Models" title="Direct link to List Installed Models">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama list</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="remove-a-model">Remove a Model<a href="#remove-a-model" class="hash-link" aria-label="Direct link to Remove a Model" title="Direct link to Remove a Model">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama rm llama2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="update-a-model">Update a Model<a href="#update-a-model" class="hash-link" aria-label="Direct link to Update a Model" title="Direct link to Update a Model">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama pull llama3.2:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="check-ollama-status">Check Ollama Status<a href="#check-ollama-status" class="hash-link" aria-label="Direct link to Check Ollama Status" title="Direct link to Check Ollama Status">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check if Ollama is running</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl http://localhost:11434/api/tags</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># View running models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec openregister-ollama ollama ps</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-tuning">Performance Tuning<a href="#performance-tuning" class="hash-link" aria-label="Direct link to Performance Tuning" title="Direct link to Performance Tuning">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="memory-configuration">Memory Configuration<a href="#memory-configuration" class="hash-link" aria-label="Direct link to Memory Configuration" title="Direct link to Memory Configuration">‚Äã</a></h3>
<p>Adjust model context size in OpenRegister settings:</p>
<ul>
<li><strong>Max Tokens</strong>: Control response length (default: 2048)</li>
<li><strong>Temperature</strong>: Control randomness (0.0-1.0, default: 0.7)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="concurrent-requests">Concurrent Requests<a href="#concurrent-requests" class="hash-link" aria-label="Direct link to Concurrent Requests" title="Direct link to Concurrent Requests">‚Äã</a></h3>
<p>Ollama can handle multiple concurrent requests. Monitor resource usage:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check container resource usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker stats openregister-ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="environment-variables">Environment Variables<a href="#environment-variables" class="hash-link" aria-label="Direct link to Environment Variables" title="Direct link to Environment Variables">‚Äã</a></h3>
<p>Edit <code>docker-compose.yml</code> to tune performance:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">environment</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Number of concurrent requests (default: 4)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_NUM_PARALLEL=8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># How long to keep models in memory (default: 30m)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_KEEP_ALIVE=1h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Maximum models to keep loaded (default: 2)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OLLAMA_MAX_LOADED_MODELS=3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="troubleshooting">Troubleshooting<a href="#troubleshooting" class="hash-link" aria-label="Direct link to Troubleshooting" title="Direct link to Troubleshooting">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="connection-error-failed-to-connect-to-localhost-port-11434">Connection Error: &quot;Failed to connect to localhost port 11434&quot;<a href="#connection-error-failed-to-connect-to-localhost-port-11434" class="hash-link" aria-label="Direct link to Connection Error: &quot;Failed to connect to localhost port 11434&quot;" title="Direct link to Connection Error: &quot;Failed to connect to localhost port 11434&quot;">‚Äã</a></h3>
<p><strong>Symptoms:</strong></p>
<ul>
<li>Error: &quot;cURL error 7: Failed to connect to localhost port 11434&quot;</li>
<li>Error: &quot;Could not connect to server&quot;</li>
<li>Chat test fails with connection refused</li>
</ul>
<p><strong>Cause:</strong> You&#x27;re using <code>http://localhost:11434</code> in OpenRegister settings, but inside the Nextcloud container, <code>localhost</code> refers to the container itself, not the host machine.</p>
<p><strong>Solution:</strong></p>
<ol>
<li>
<p><strong>Update Ollama URL in OpenRegister settings:</strong></p>
<ul>
<li>Go to <strong>Settings</strong> ‚Üí <strong>OpenRegister</strong> ‚Üí <strong>LLM Configuration</strong></li>
<li>Change Ollama URL from <code>http://localhost:11434</code> to <code>http://openregister-ollama:11434</code></li>
<li>Click <strong>Save</strong> and <strong>Test Connection</strong></li>
</ul>
</li>
<li>
<p><strong>Verify containers are on the same network:</strong></p>
</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check if Nextcloud can reach Ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec master-nextcloud-1 curl -s http://openregister-ollama:11434/api/tags</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Should return JSON with model list</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ol start="3">
<li><strong>If still failing, connect containers to the same network:</strong></li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Find your Nextcloud network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker network ls | grep master</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Connect Ollama to the same network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker network connect master_default openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Test again</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec master-nextcloud-1 curl -s http://openregister-ollama:11434/api/tags</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Remember:</strong> Always use the <strong>container/service name</strong>, not <code>localhost</code>, when configuring services inside Docker.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-not-found-404-error">Model Not Found (404 Error)<a href="#model-not-found-404-error" class="hash-link" aria-label="Direct link to Model Not Found (404 Error)" title="Direct link to Model Not Found (404 Error)">‚Äã</a></h3>
<p><strong>Cause:</strong> Model name doesn&#x27;t include version tag.</p>
<p><strong>Solution:</strong> Use full model name with tag:</p>
<ul>
<li>‚úÖ <code>mistral:7b</code> (correct)</li>
<li>‚ùå <code>mistral</code> (wrong - missing tag)</li>
</ul>
<p>Update model name in OpenRegister settings to include the tag.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ollama-container-not-starting">Ollama Container Not Starting<a href="#ollama-container-not-starting" class="hash-link" aria-label="Direct link to Ollama Container Not Starting" title="Direct link to Ollama Container Not Starting">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker logs openregister-ollama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Restart the container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker-compose restart ollama</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="out-of-memory">Out of Memory<a href="#out-of-memory" class="hash-link" aria-label="Direct link to Out of Memory" title="Direct link to Out of Memory">‚Äã</a></h3>
<ol>
<li>Use a smaller model (phi3<!-- -->:mini<!-- -->, mistral:7b)</li>
<li>Reduce max tokens in settings</li>
<li>Allocate more RAM to Docker</li>
<li>Stop other services temporarily</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="slow-responses">Slow Responses<a href="#slow-responses" class="hash-link" aria-label="Direct link to Slow Responses" title="Direct link to Slow Responses">‚Äã</a></h3>
<ol>
<li>Use a faster model (mistral:7b, phi3<!-- -->:mini<!-- -->)</li>
<li>Reduce context window</li>
<li>Enable GPU support</li>
<li>Check system resources: <code>docker stats</code></li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model-recommendations-by-use-case">Model Recommendations by Use Case<a href="#model-recommendations-by-use-case" class="hash-link" aria-label="Direct link to Model Recommendations by Use Case" title="Direct link to Model Recommendations by Use Case">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="general-customer-support">General Customer Support<a href="#general-customer-support" class="hash-link" aria-label="Direct link to General Customer Support" title="Direct link to General Customer Support">‚Äã</a></h3>
<ul>
<li><strong>Model</strong>: llama3.2<!-- -->:latest<!-- --> or mistral:7b</li>
<li><strong>Why</strong>: Good balance of quality and speed</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="technical-documentation">Technical Documentation<a href="#technical-documentation" class="hash-link" aria-label="Direct link to Technical Documentation" title="Direct link to Technical Documentation">‚Äã</a></h3>
<ul>
<li><strong>Model</strong>: codellama<!-- -->:latest</li>
<li><strong>Why</strong>: Better understanding of technical content</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="low-resource-environments">Low Resource Environments<a href="#low-resource-environments" class="hash-link" aria-label="Direct link to Low Resource Environments" title="Direct link to Low Resource Environments">‚Äã</a></h3>
<ul>
<li><strong>Model</strong>: phi3<!-- -->:mini</li>
<li><strong>Why</strong>: Smallest footprint while maintaining quality</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="maximum-quality">Maximum Quality<a href="#maximum-quality" class="hash-link" aria-label="Direct link to Maximum Quality" title="Direct link to Maximum Quality">‚Äã</a></h3>
<ul>
<li><strong>Model</strong>: llama3.2:70b (requires 64GB+ RAM)</li>
<li><strong>Why</strong>: Best possible responses (if you have the resources)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="security-considerations">Security Considerations<a href="#security-considerations" class="hash-link" aria-label="Direct link to Security Considerations" title="Direct link to Security Considerations">‚Äã</a></h2>
<ol>
<li><strong>Network Isolation</strong>: Ollama is only accessible within the Docker network by default</li>
<li><strong>No External API Calls</strong>: All processing happens locally</li>
<li><strong>Data Privacy</strong>: Your data never leaves your infrastructure</li>
<li><strong>Model Safety</strong>: Use official models from Ollama library</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources">‚Äã</a></h2>
<ul>
<li><strong>Ollama Documentation</strong>: <a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer">https://ollama.ai/</a></li>
<li><strong>Model Library</strong>: <a href="https://ollama.ai/library" target="_blank" rel="noopener noreferrer">https://ollama.ai/library</a></li>
<li><strong>GitHub</strong>: <a href="https://github.com/ollama/ollama" target="_blank" rel="noopener noreferrer">https://github.com/ollama/ollama</a></li>
<li><strong>OpenRegister AI Docs</strong>: See <a href="/docs/features/ai">AI Features</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="faq">FAQ<a href="#faq" class="hash-link" aria-label="Direct link to FAQ" title="Direct link to FAQ">‚Äã</a></h2>
<p><strong>Q: Can I use multiple models simultaneously?</strong><br>
<!-- -->A: Yes, configure different models for chat vs embeddings.</p>
<p><strong>Q: How much disk space do I need?</strong><br>
<!-- -->A: Plan for 5-10GB per model. Embedding models are smaller (~500MB).</p>
<p><strong>Q: Can I use custom models?</strong><br>
<!-- -->A: Yes, see Ollama documentation on creating custom Modelfiles.</p>
<p><strong>Q: Does it work on ARM (Apple Silicon)?</strong><br>
<!-- -->A: Yes, Ollama supports ARM64 architecture.</p>
<p><strong>Q: Can I use Ollama with other OpenRegister apps?</strong><br>
<!-- -->A: Yes, any app in the workspace can access the Ollama container.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/conductionnl/openregister/tree/main/website/docs/development/ollama.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/development/performance-optimization"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Performance Optimization</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/development/tool-registration"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Tool Registration</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-ollama" class="table-of-contents__link toc-highlight">What is Ollama?</a><ul><li><a href="#technical-implementation" class="table-of-contents__link toc-highlight">Technical Implementation</a></li></ul></li><li><a href="#quick-start" class="table-of-contents__link toc-highlight">Quick Start</a><ul><li><a href="#1-start-ollama-container" class="table-of-contents__link toc-highlight">1. Start Ollama Container</a></li><li><a href="#2-pull-a-model" class="table-of-contents__link toc-highlight">2. Pull a Model</a></li><li><a href="#3-configure-openregister" class="table-of-contents__link toc-highlight">3. Configure OpenRegister</a></li><li><a href="#4-pull-embedding-model-for-rag" class="table-of-contents__link toc-highlight">4. Pull Embedding Model (for RAG)</a></li></ul></li><li><a href="#configuration-details" class="table-of-contents__link toc-highlight">Configuration Details</a><ul><li><a href="#ollama-service-configuration" class="table-of-contents__link toc-highlight">Ollama Service Configuration</a></li><li><a href="#accessing-ollama" class="table-of-contents__link toc-highlight">Accessing Ollama</a></li><li><a href="#model-naming" class="table-of-contents__link toc-highlight">Model Naming</a></li></ul></li><li><a href="#recommended-models" class="table-of-contents__link toc-highlight">Recommended Models</a><ul><li><a href="#for-chat--agents" class="table-of-contents__link toc-highlight">For Chat &amp; Agents</a></li><li><a href="#for-embeddings-rag" class="table-of-contents__link toc-highlight">For Embeddings (RAG)</a></li></ul></li><li><a href="#gpu-support" class="table-of-contents__link toc-highlight">GPU Support</a><ul><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#verify-wsl-gpu-support-windows--wsl" class="table-of-contents__link toc-highlight">Verify WSL GPU Support (Windows + WSL)</a></li><li><a href="#verify-docker-gpu-support" class="table-of-contents__link toc-highlight">Verify Docker GPU Support</a></li><li><a href="#enable-gpu-in-docker-compose" class="table-of-contents__link toc-highlight">Enable GPU in Docker Compose</a></li><li><a href="#apply-gpu-configuration" class="table-of-contents__link toc-highlight">Apply GPU Configuration</a></li><li><a href="#verify-gpu-is-working" class="table-of-contents__link toc-highlight">Verify GPU is Working</a></li><li><a href="#performance-comparison" class="table-of-contents__link toc-highlight">Performance Comparison</a></li><li><a href="#gpu-troubleshooting" class="table-of-contents__link toc-highlight">GPU Troubleshooting</a></li></ul></li><li><a href="#standalone-setup" class="table-of-contents__link toc-highlight">Standalone Setup</a><ul><li><a href="#start-standalone-ollama" class="table-of-contents__link toc-highlight">Start Standalone Ollama</a></li><li><a href="#configure-openregister-for-standalone" class="table-of-contents__link toc-highlight">Configure OpenRegister for Standalone</a></li></ul></li><li><a href="#using-ollama-features" class="table-of-contents__link toc-highlight">Using Ollama Features</a><ul><li><a href="#1-chat" class="table-of-contents__link toc-highlight">1. Chat</a></li><li><a href="#2-rag-retrieval-augmented-generation" class="table-of-contents__link toc-highlight">2. RAG (Retrieval Augmented Generation)</a></li><li><a href="#3-agents-with-tools" class="table-of-contents__link toc-highlight">3. Agents with Tools</a></li></ul></li><li><a href="#managing-models" class="table-of-contents__link toc-highlight">Managing Models</a><ul><li><a href="#list-installed-models" class="table-of-contents__link toc-highlight">List Installed Models</a></li><li><a href="#remove-a-model" class="table-of-contents__link toc-highlight">Remove a Model</a></li><li><a href="#update-a-model" class="table-of-contents__link toc-highlight">Update a Model</a></li><li><a href="#check-ollama-status" class="table-of-contents__link toc-highlight">Check Ollama Status</a></li></ul></li><li><a href="#performance-tuning" class="table-of-contents__link toc-highlight">Performance Tuning</a><ul><li><a href="#memory-configuration" class="table-of-contents__link toc-highlight">Memory Configuration</a></li><li><a href="#concurrent-requests" class="table-of-contents__link toc-highlight">Concurrent Requests</a></li><li><a href="#environment-variables" class="table-of-contents__link toc-highlight">Environment Variables</a></li></ul></li><li><a href="#troubleshooting" class="table-of-contents__link toc-highlight">Troubleshooting</a><ul><li><a href="#connection-error-failed-to-connect-to-localhost-port-11434" class="table-of-contents__link toc-highlight">Connection Error: &quot;Failed to connect to localhost port 11434&quot;</a></li><li><a href="#model-not-found-404-error" class="table-of-contents__link toc-highlight">Model Not Found (404 Error)</a></li><li><a href="#ollama-container-not-starting" class="table-of-contents__link toc-highlight">Ollama Container Not Starting</a></li><li><a href="#out-of-memory" class="table-of-contents__link toc-highlight">Out of Memory</a></li><li><a href="#slow-responses" class="table-of-contents__link toc-highlight">Slow Responses</a></li></ul></li><li><a href="#model-recommendations-by-use-case" class="table-of-contents__link toc-highlight">Model Recommendations by Use Case</a><ul><li><a href="#general-customer-support" class="table-of-contents__link toc-highlight">General Customer Support</a></li><li><a href="#technical-documentation" class="table-of-contents__link toc-highlight">Technical Documentation</a></li><li><a href="#low-resource-environments" class="table-of-contents__link toc-highlight">Low Resource Environments</a></li><li><a href="#maximum-quality" class="table-of-contents__link toc-highlight">Maximum Quality</a></li></ul></li><li><a href="#security-considerations" class="table-of-contents__link toc-highlight">Security Considerations</a></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a></li><li><a href="#faq" class="table-of-contents__link toc-highlight">FAQ</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/conductionnl/openregister" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 for <a href="https://openwebconcept.nl">Open Webconcept</a> by <a href="https://conduction.nl">Conduction B.V.</a></div></div></div></footer></div>
</body>
</html>